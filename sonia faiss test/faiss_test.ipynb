{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sonia/Development/SF_WanderChat/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sonia/Development/SF_WanderChat/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the current travel advisory for Gaza?</td>\n",
       "      <td>The advisory recommends not traveling to Gaza ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why should travelers reconsider visiting Israe...</td>\n",
       "      <td>Travelers should reconsider due to ongoing ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What precautions should U.S. citizens take if ...</td>\n",
       "      <td>Travelers should maintain situational awarenes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are there any specific travel restrictions for...</td>\n",
       "      <td>Yes, U.S. government employees have travel res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What should individuals do if they absolutely ...</td>\n",
       "      <td>They should prepare for an indefinite stay, ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0      What is the current travel advisory for Gaza?   \n",
       "1  Why should travelers reconsider visiting Israe...   \n",
       "2  What precautions should U.S. citizens take if ...   \n",
       "3  Are there any specific travel restrictions for...   \n",
       "4  What should individuals do if they absolutely ...   \n",
       "\n",
       "                                              Answer  \n",
       "0  The advisory recommends not traveling to Gaza ...  \n",
       "1  Travelers should reconsider due to ongoing ter...  \n",
       "2  Travelers should maintain situational awarenes...  \n",
       "3  Yes, U.S. government employees have travel res...  \n",
       "4  They should prepare for an indefinite stay, ha...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def text_to_vector(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv('israel.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to vectors\n",
    "q_vectors = np.vstack([text_to_vector(text) for text in df['Question']])\n",
    "a_vectors = np.vstack([text_to_vector(text) for text in df['Answer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "df = pd.read_csv('israel.csv')\n",
    "data = df[['feature1', 'feature2', 'feature3']].values  # Assuming these are your vector features\n",
    "data = data.astype('float32')\n",
    "\n",
    "# Build the index\n",
    "dimension = data.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(data)\n",
    "\n",
    "# Optionally save the index to disk\n",
    "faiss.write_index(index, 'your_index.faiss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and the RAG model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create FAISS index\n",
    "def create_index(data, dimension):\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(data.astype('float32'))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and create FAISS index\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    data_vectors = df.to_numpy()\n",
    "    index = create_index(data_vectors, data_vectors.shape[1])\n",
    "    return index, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit interface\n",
    "st.title('RAG with FAISS for Information Retrieval')\n",
    "\n",
    "csv_file = st.file_uploader(\"Upload your CSV\", type=['csv'])\n",
    "if csv_file is not None:\n",
    "    index, df = load_data(csv_file)\n",
    "    st.success('Data loaded and index created!')\n",
    "\n",
    "    # Text input for query\n",
    "    query = st.text_area(\"Enter your query here:\")\n",
    "    if st.button('Generate Answer'):\n",
    "        if query:\n",
    "            # Retrieve context from FAISS index\n",
    "            input_ids = tokenizer(query, return_tensors=\"pt\").input_ids\n",
    "            retrieved = model.context_encoder(input_ids)[0]  # Context encoding\n",
    "            distances, indices = index.search(retrieved.detach().numpy(), 1)  # Search in FAISS\n",
    "            context = df.iloc[indices[0][0]]['text_column_name']  # Adjust column name\n",
    "\n",
    "            # Generate answer using RAG\n",
    "            inputs = tokenizer(context + \" \\\\n \" + query, return_tensors=\"pt\")\n",
    "            outputs = model.generate(**inputs)\n",
    "            answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            st.write(answer)\n",
    "        else:\n",
    "            st.error(\"Please enter a query to generate an answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
